{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPS\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ FILE \n",
    "df_dib = pd.read_csv(\"charge_survey_DIABETES_LEFT_Mrgdata.csv\")\n",
    "df_jnt = pd.read_csv(\"chrg_survy_JOINT__FULLMERGE1_data.csv\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT YOUR STATE FROM EACH MERGE FILE \n",
    "\n",
    "# INSERT YOU NAME\n",
    "# RON, BRANDON, OR TYLER BELOW :\n",
    "my_name_is = '--put your name here--'\n",
    "\n",
    "# SPECIFY PARAMETERS\n",
    "state_a = '!!!--put your state ABBREV  AL,CA,ETC.. here--!!!'\n",
    "state_b = '!!!--put your state ABBREV  AL,CA,ETC.. here--!!!'\n",
    "\n",
    "# DIABETES - EXTRACT ALL ROWS  FOR TWO DIFF STATES  -\n",
    "dib_state_a    = df_dib.loc[df_dib[\"State\"] == state_a, :]\n",
    "dib_state_b    = df_dib.loc[df_dib[\"State\"] == state_b  :]\n",
    "\n",
    "# JOINTS - EXTRACT ALL ROWS  FOR TWO DIFF STATES  -\n",
    "jnt_state_a = df_jnt.loc[df_jnt[\"State\"] == state_a,  :]\n",
    "jnt_state_b = df_jnt.loc[df_jnt[\"State\"] == state_b,  :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CSV'S BY STATE ??? \n",
    "\n",
    "# DO YOU WANT TO SAVE AS NEW CSV'S -U CAN CHART WITHOUT SAVING CSV\n",
    "# HOLD  CTRL + '/'  TO UNCOMMENT AND SAVE OUT FILES \n",
    "\n",
    "# dib_state_a.to_csv( f\"DIABETES_BY_STATE__{state_a}_{my_name_is}_.csv\", index=False)\n",
    "# dib_state_b.to_csv( f\"DIABETES_BY_STATE__{state_a}_{my_name_is}_.csv\", index=False)\n",
    "# jnt_state_a.to_csv( f\"JOINTS_BY_STATE__{state_a}_{my_name_is}_.csv\", index=False)\n",
    "# jnt_state_b.to_csv( f\"JOINTS_BY_STATE__{state_a}_{my_name_is}_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WANT TO EXTRACT BY CITY / REGION \n",
    "\n",
    "## |  DIABETES   | \n",
    "#-------------------------------------------------------------------------------------------\n",
    "# INSERT - NAMES OF CITYS / REGIONS \n",
    "dib_city_region_a = '-put region here-'  #  EXAMPLE = 'CA - Los Angeles' see your csv for exact region\n",
    "dib_city_region_b = '-put region here-'  #  EXAMPLE = 'CA - Los Angeles' see your csv for exact region\n",
    "# EXTRACT CITY REGION \n",
    "dib_city_reg_a    = df_dib.loc[df_dib[\"Hospital Referral Region (HRR) Description\"] == dib_city_region_a, :]\n",
    "dib_city_reg_b    = df_dib.loc[df_dib[\"Hospital Referral Region (HRR) Description\"] == dib_city_region_b, :]\n",
    "\n",
    "## |  JOINTS   | \n",
    "#-------------------------------------------------------------------------------------------\n",
    "# INSERT -  NAMES OF CITYS / REGIONS \n",
    "jnt_city_region_a = '-put region here-'  #  EXAMPLE = 'CA - Los Angeles' see your csv for exact region\n",
    "jnt_city_region_b = '-put region here-'  #  EXAMPLE = 'CA - Los Angeles' see your csv for exact region\n",
    "# EXTRACT CITY REGION \n",
    "jnt_city_reg_a    = df_dib.loc[df_dib[\"Hospital Referral Region (HRR) Description\"] == jnt_city_region_a, :]\n",
    "jnt_city_reg_b    = df_dib.loc[df_dib[\"Hospital Referral Region (HRR) Description\"] == jnt_city_region_b, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CSV'S BY CITY REGION ??? \n",
    "\n",
    "# DO YOU WANT TO SAVE AS NEW CSV'S -U CAN CHART WITHOUT SAVING CSV\n",
    "# HOLD  CTRL + '/'  TO UNCOMMENT AND SAVE OUT FILES \n",
    "\n",
    "# dib_city_reg_a.to_csv( f\"DIABETES_BY_STATE__{dib_city_region_a}_{my_name_is}_.csv\", index=False)\n",
    "# dib_city_reg_b.to_csv( f\"DIABETES_BY_STATE__{dib_city_region_b}_{my_name_is}_.csv\", index=False)\n",
    "# jnt_city_reg_a.to_csv( f\"JOINTS_BY_STATE__{dib_city_reg_a}_{my_name_is}_.csv\", index=False)\n",
    "# jnt_city_reg_b.to_csv( f\"JOINTS_BY_STATE__{dib_city_reg_b}_{my_name_is}_.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE SCATTER CHART OTHER CHART EXAMPLES BELOW \n",
    "# FILL IN YOUR DATA BELOW \n",
    "with plt.style.context(('seaborn-white')):  # !! -- I NOW RUN JUPYTER NOTEBOOK DARK MODE AND HAVE TO SET WHITE BACKGROUNDS FOR MY CHARTS -- !!\n",
    "        plt.grid()\n",
    "        plt.scatter('FOR X - YOUR DF[COLUMN]', 'FOR X - YOUR DF[COLUMN]', c='steelblue',  alpha= .85, edgecolor = 'k', linewidth=1 ,zorder=-1 )\n",
    "        plt.title(\"YOUR CHART TITLE\", clip_on =True) # TITLE OF CHART\n",
    "        plt.xlabel(\"YOUR X AXIS LABEL\")  # LABEL THE X AXIS\n",
    "        plt.ylabel(\"YOUR Y AXIS LABEL\") # LABEL THE Y AXIS\n",
    "        plt.autoscale()# make chart fit any cell or window size ,    #plt.tight_layout() # avoid overlapping labels \n",
    "        plt.savefig(\"YOUR FILE NAME__YOUR_FIRST_NAME.png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLES OF BAR, PIE CHARTS \n",
    "\n",
    "https://python-graph-gallery.com/\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html\n",
    "\n",
    "\n",
    " { BAR  VERTICLE HORIZ STACKED }\n",
    "with plt.style.context(('seaborn-white')):    \n",
    "        #basic bar \n",
    "    df_NAME.plot.bar();\n",
    "        #To produce a stacked bar plot\n",
    "    df_NAME.plot.bar(stacked=True);\n",
    "        #To get horizontal bar plots, use the barh method:\n",
    "    df_NAME.plot.barh(stacked=True); \n",
    "    \n",
    "* { BAR CHART - dataframe.plot EXAMPLE  }\n",
    "with plt.style.context(('seaborn-white')):\n",
    "    bike_ct.plot(kind = 'bar' , facecolor = 'red',   title=\"Bike Trips by Gender\") \n",
    "    bike_ct.set_xlabel(\"Gender\")\n",
    "    bike_ct.set_ylabel(\"Number of Trips Taken\")\n",
    "    \n",
    "\n",
    "* { BAR CHART - plt.bar - EXAMPLE   }\n",
    "with plt.style.context(('seaborn-white')): \n",
    "    cities = [\"New Orleans\", \"Milwaukee\", \"Omaha\", \"Pittsburgh\", \"Toledo\"]\n",
    "    bars_in_cities = [8.6, 8.5, 8.3, 7.9, 7.2]\n",
    "    x_axis = np.arange(len(bars_in_cities))\n",
    "    plt.bar(x_axis, bars_in_cities, color = \"blue\" , label = \"Top 5 Bars\")\n",
    "    plt.xticks(x_axis, cities)\n",
    "    plt.ylim(.5,9)\n",
    "    plt.xlabel(\"Cities \")\n",
    "    plt.ylabel(\"Bars Per 10,0000 HouseHolds \")\n",
    "    plt.title(\"Density of Bars in Cities\")\n",
    "    plt.figure(figsize=(8,3))# BS i think this sets size of chart\n",
    "    plt.savefig(\"basic_cos_sin3.png\")\n",
    "\n",
    "* { EXAMPLE PIE CHART }  \n",
    "* VALUES -\n",
    "urb__ride_t  = urban_gp[\"number of rides\"].sum()\n",
    "surb_ride_t  = suburban_gp[\"number of rides\"].sum()\n",
    "rur__ride_t  = rural_gp[\"number of rides\"].sum()\n",
    "ride_t       = urb__ride_t  + surb_ride_t  + rur__ride_t\n",
    "\n",
    "with plt.style.context(('ggplot')):\n",
    "    print(plt.style.available)  #print this to see all options for parameter you can pass into plt.style.use() \n",
    "    labelss = ['Urban',  'Rural', 'Suburban']\n",
    "    valss   = [urb__ride_t, rur__ride_t, surb_ride_t ]\n",
    "    #colorss = ['coral', 'gold','skyblue'] #['lightcoral', 'gold','skyblue']\n",
    "    colorss = ['lightcoral', 'gold','skyblue'] # !! TAs  I HAD TO USE LIGHTCORAL TO MATCH SAMPLE, CORAL COMES OUT \n",
    "    explodes= [ .1, 0, 0]\n",
    "    plt.pie(valss, explode=explodes, labels=labelss, colors=colorss,  autopct=\"%1.1f%%\", shadow=True , startangle= 250)\n",
    "    plt.axis(\"tight\")\n",
    "    plt.title('% Percent of Total Rides by City Type')\n",
    "    plt.savefig(\"YOUR FILE NAME.png\")\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPFUL SYNTAX\n",
    "df.sort_values(col1) | Sort values by col1 in ascending order\n",
    "df.sort_values(col2,ascending=False) | Sort values by col2 in descending order\n",
    "df.sort_values([col1,col2],ascending=[True,False]) | Sort values by col1 in ascending order then col2 in descending order\n",
    " \n",
    "/// sort by  -ascending yes or no :\n",
    "df_NAME  = df_NAME.sort_values(by='exact col name', ascending = False)\n",
    "\n",
    "df.describe() | Summary statistics for numerical columns\n",
    "df.mean() | Returns the mean of all columns\n",
    "df.corr() | Returns the correlation between columns in a DataFrame\n",
    "df.count() | Returns the number of non-null values in each DataFrame column\n",
    "df.max() | Returns the highest value in each column\n",
    "df.min() | Returns the lowest value in each column\n",
    "df.median() | Returns the median of each column\n",
    "df.std() | Returns the standard deviation of each column\n",
    "\n",
    "Viewing/Inspecting Data\n",
    "df.head(n) | First n rows of the DataFrame\n",
    "df.tail(n) | Last n rows of the DataFrame\n",
    "df.shape | Number of rows and columns\n",
    "df.info() | Index, Datatype and Memory information\n",
    "df.describe() | Summary statistics for numerical columns\n",
    "s.value_counts(dropna=False) | View unique values and counts\n",
    "df.apply(pd.Series.value_counts) | Unique values and counts for all columns\n",
    "\n",
    "Selection\n",
    "df[col] | Returns column with label col as Series\n",
    "df[[col1, col2]] | Returns columns as a new DataFrame\n",
    "s.iloc[0] | Selection by position\n",
    "s.loc['index_one'] | Selection by index\n",
    "df.iloc[0,:] | First row\n",
    "df.iloc[0,0] | First element of first column\n",
    "\n",
    "Data Cleaning\n",
    "df.columns = ['a','b','c'] | Rename columns\n",
    "pd.isnull() | Checks for null Values, Returns Boolean Arrray\n",
    "pd.notnull() | Opposite of pd.isnull()\n",
    "df.dropna() | Drop all rows that contain null values\n",
    "df.dropna(axis=1) | Drop all columns that contain null values\n",
    "df.dropna(axis=1,thresh=n) | Drop all rows have have less than n non null values\n",
    "df.fillna(x) | Replace all null values with x\n",
    "s.fillna(s.mean()) | Replace all null values with the mean (mean can be replaced with almost any function from the statistics module)\n",
    "\n",
    "s.astype(float) | Convert the datatype of the series to float\n",
    "s.replace(1,'one') | Replace all values equal to 1 with 'one'\n",
    "s.replace([1,3],['one','three']) | Replace all 1 with 'one' and 3 with 'three'\n",
    "df.rename(columns=lambda x: x + 1) | Mass renaming of columns\n",
    "df.rename(columns={'old_name': 'new_ name'}) | Selective renaming\n",
    "df.set_index('column_one') | Change the index\n",
    "\n",
    "pd.read_csv(filename) | From a CSV file\n",
    "pd.read_table(filename) | From a delimited text file (like TSV)\n",
    "pd.read_excel(filename) | From an Excel file\n",
    "pd.read_sql(query, connection_object) | Read from a SQL table/database\n",
    "pd.read_json(json_string) | Read from a JSON formatted string, URL or file.\n",
    "pd.read_html(url) | Parses an html URL, string or file and extracts tables to a list of dataframes\n",
    "pd.read_clipboard() | Takes the contents of your clipboard and passes it to read_table()\n",
    "pd.DataFrame(dict) | From a dict, keys for columns names, values for data as lists"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
